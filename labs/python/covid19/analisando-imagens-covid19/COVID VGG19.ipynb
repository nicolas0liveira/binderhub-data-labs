{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício modificado e baseado no original do **Canal Sandeco - https://github.com/sandeco/CanalSandeco**\n",
    "\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEIA ORIGINAL: <br/>\n",
    "Adam Rosembrock <br/>\n",
    "pyimagesearch.com - \n",
    "https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATENÇÃO\n",
    "\n",
    "Os métodos e técnicas usados neste vídeo são apenas para fins educacionais. Esse não é um estudo cientificamente rigoroso, nem será publicado em uma revista científica´."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENDA\n",
    "\n",
    "Dentro do tutorial de hoje, você aprenderá como:\n",
    "\n",
    "- Abrir uma base de imagens de raio-X  (open data) de pacientes com resultado POSITIVO para COVID-19 e imagens de pacientes com resultado NEGATIVO.\n",
    "\n",
    "\n",
    "- Dividir o dataset de imagens em conjunto de teste e conjunto de treino \n",
    "\n",
    "\n",
    "- Aplicar a técnica de aumento de dados (Data Augmentation)\n",
    "\n",
    "\n",
    "\n",
    "- Aplicar a técnica de transferência de inteligência entre redes neurais (Transfer Learning)\n",
    "\n",
    "\n",
    "- Treinar uma Rede Neural Convolucional com o Tensorflow/Keras para detectar automaticamente o COVID-19 em imagens de raios-X \n",
    "\n",
    "\n",
    "- Avaliar os resultados sob uma perspectiva educacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_image(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((150,150))\n",
    "    # convert to array\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(diretorio, classe, imagens, labels):\n",
    "    # iterando arquivos\n",
    "    \n",
    "    if diretorio == \".direcory\" or classe == \".directory\":\n",
    "        return imagens, labels\n",
    "    \n",
    "    for filename in listdir(diretorio):\n",
    "        if filename == \".directory\":\n",
    "            continue\n",
    "        \n",
    "        path = diretorio + filename\n",
    "        try:           \n",
    "            imagens.append(select_image(path))\n",
    "            labels.append(classe)\n",
    "        except:\n",
    "            print(\"Erro ao ler imagem {}\".format(path))\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_set(diretorio):\n",
    "\n",
    "    imagens = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir in listdir(diretorio):\n",
    "        # path\n",
    "        path = diretorio + subdir + '/'\n",
    "\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        imagens, labels = load_classes(path, subdir, imagens, labels)\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dataset Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dataset = \"/home/nicolas/dev/github/data-garage/python/covid19/analisando-imagens-covid19/dataset/\"  #imagens médicas/dataset/\n",
    "imagens, labels  = select_data_set(covid_dataset)\n",
    "imagens = np.array(imagens) / 255.0  ## convertendo de lista para array\n",
    "labels = np.array(labels)  ## convertendo de lista para array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 150, 150, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando classes - Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[0., 1.],\n",
       "        [1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = 32 #tamanho do lote (Lotes de X imagens)\n",
    "input_shape  = (150, 150, 3) \n",
    "random_state = 42 #serve para que possamos reproduzir o experimento\n",
    "alpha        = 1e-5 #Taxa de aprendizado\n",
    "epoch        = 100 #treinar por 100 epocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLBACKS\n",
    "\n",
    "Callback são classes que auxiliam o treinamento do modelo usando o Keras. As classes que usaremos são:\n",
    "\n",
    "- ModelCheckpoint\n",
    "- ReduceLROnPlateau\n",
    "- EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint\n",
    "\n",
    "ModelCheckpoint nos ajudará a salvar o modelo para cada época, para que possamos treinar nosso modelo e não nos preocuparmos com possíveis problemas que possam acontecer, como travamento da máquina.\n",
    "\n",
    "- **filepath**: onde será salvo o modelo\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n",
    "- **save_best_only**: Salvar somente o melhor modelo\n",
    "- **mode**: como vamos monitorar o 'val_acc' o valor aqui vai ser 'max'. Queremos a máxima acurácia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau\n",
    "\n",
    "Nos auxiliara a reduzir a taxa de aprendizado pelo fator (factor) caso não ocorra a mudança no loss.\n",
    "\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **factor**: fator de redução caso estejamos em um plator\n",
    "- **min_delta**: valor mínimo da perda\n",
    "- **patience**: só altere pelo fator após se repitir por 'patience' vezes.\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=alpha, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array de Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, lr_reduce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando dataset em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(imagens, labels, test_size=0.20, stratify=labels, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 150, 150, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION\n",
    "Ter um grande conjunto de dados é crucial para o desempenho do modelo baseado em Deep Learning. Como nosso conjunto não é tão grande, podemos usar a técnica de 'Aumento de dados' para melhorar o desempenho do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "train_datagen.fit(trainX)\n",
    "\n",
    "data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING\n",
    "\n",
    "* **weights:** qual base de imagens de treino\n",
    "* **include_top:** se deve incluir a camada totalmente conectada na parte superior da rede\n",
    "* **input_shape:** formato da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreinando parte da VGG19\n",
    "\n",
    "#### Ajuste fino\n",
    "\n",
    "As camadas iniciais aprendem características muito gerais e à medida que descemos (deep) a rede, as camadas tendem a aprender padrões mais específicos para a tarefa em que está sendo treinada.\n",
    "\n",
    "Assim, no ajuste fino, queremos manter intactas as camadas iniciais (ou congelá-las) e treinar novamente as camadas inferiores para que ela possa entender nossos padrões.\n",
    "\n",
    "O ajuste fino ajuda em duas limitações:\n",
    "\n",
    "* Nossa quantidade de dados necessária para o treinamento não é grande, porém podemos dar mais capacidade de entendimento a rede pré-treinada. Porém, não estamos retreinando toda a rede.\n",
    "* Segundo, a parte que está sendo retreinada não é treinada do zero. Como os parâmetros que precisam ser treinados são menores, a quantidaade de tempo de processamento necessária também será menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRIANDO O MODELO COM A VGG19 COMO BASE\n",
    "\n",
    "* **GlobalAvaregePooling2D:** Realizar pooling (redução de resolução(pela média global)\n",
    "* **BatchNormalization:** Aumentar a estabilidade de uma rede neural aplicando normalizações em meio ao treinamento\n",
    "* **Flatton:** analiar imagem pela camada densa\n",
    "* **Dense:** Camada densa da rede neual/Relu: ativação para imagens\n",
    "* **Dropout**: Regularização para melhorar a generalidade da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 20,092,354\n",
      "Trainable params: 9,506,178\n",
      "Non-trainable params: 10,586,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILANDO O MODELO\n",
    "\n",
    "* loss: binary cross entropy (loss = erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREINANDO O MODELO\n",
    "\n",
    "***Obs: não treinar na hora da live***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-157b40edf3b9>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 3 steps, validate on 26 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 1.3301 - acc: 0.5000 \n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.0648 - acc: 0.5286 - val_loss: 2.2522 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.3566 - acc: 0.8947 \n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.3247 - acc: 0.8857 - val_loss: 7.6685 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2825 - acc: 0.8906 \n",
      "Epoch 00003: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 27s 9s/step - loss: 0.4650 - acc: 0.8857 - val_loss: 7.6685 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.5294 - acc: 0.8158\n",
      "Epoch 00004: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.4712 - acc: 0.8143 - val_loss: 7.6666 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "2/3 [===================>..........] - ETA: 10s - loss: 0.2874 - acc: 0.8438\n",
      "Epoch 00005: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.2947 - acc: 0.8429 - val_loss: 7.5371 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2931 - acc: 0.9062 \n",
      "Epoch 00006: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.3026 - acc: 0.8857 - val_loss: 7.6685 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2253 - acc: 0.9062 \n",
      "Epoch 00007: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.1894 - acc: 0.9375 - val_loss: 7.3697 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2151 - acc: 0.9531 \n",
      "Epoch 00008: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 34s 11s/step - loss: 0.2055 - acc: 0.9479 - val_loss: 7.1217 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1582 - acc: 0.9474\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1819 - acc: 0.9286 - val_loss: 6.7171 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.4194 - acc: 0.8684\n",
      "Epoch 00010: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 27s 9s/step - loss: 0.3172 - acc: 0.9143 - val_loss: 6.2810 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.2025 - acc: 0.9211\n",
      "Epoch 00011: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3/3 [==============================] - 27s 9s/step - loss: 0.1706 - acc: 0.9286 - val_loss: 5.8823 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "2/3 [===================>..........] - ETA: 10s - loss: 0.1440 - acc: 0.9688\n",
      "Epoch 00012: val_acc did not improve from 0.50000\n",
      "3/3 [==============================] - 36s 12s/step - loss: 0.2157 - acc: 0.9479 - val_loss: 5.3767 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "2/3 [===================>..........] - ETA: 10s - loss: 0.1958 - acc: 0.9375\n",
      "Epoch 00013: val_acc improved from 0.50000 to 0.53846, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 30s 10s/step - loss: 0.1901 - acc: 0.9429 - val_loss: 5.0515 - val_acc: 0.5385\n",
      "Epoch 14/100\n",
      "2/3 [===================>..........] - ETA: 3s - loss: 0.2933 - acc: 0.8421\n",
      "Epoch 00014: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2264 - acc: 0.9143 - val_loss: 4.6974 - val_acc: 0.5385\n",
      "Epoch 15/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.1835 - acc: 0.9219 \n",
      "Epoch 00015: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.1665 - acc: 0.9167 - val_loss: 4.1383 - val_acc: 0.5385\n",
      "Epoch 16/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.1415 - acc: 0.9531 \n",
      "Epoch 00016: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.1887 - acc: 0.9429 - val_loss: 3.7563 - val_acc: 0.5385\n",
      "Epoch 17/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1047 - acc: 1.0000 \n",
      "Epoch 00017: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.1695 - acc: 0.9429 - val_loss: 3.4919 - val_acc: 0.5385\n",
      "Epoch 18/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2027 - acc: 0.8906 \n",
      "Epoch 00018: val_acc did not improve from 0.53846\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.1823 - acc: 0.9167 - val_loss: 3.1276 - val_acc: 0.5385\n",
      "Epoch 19/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.1851 - acc: 0.9375 \n",
      "Epoch 00019: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.3041 - acc: 0.9143 - val_loss: 2.9163 - val_acc: 0.5385\n",
      "Epoch 20/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2441 - acc: 0.9062 \n",
      "Epoch 00020: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 27s 9s/step - loss: 0.2103 - acc: 0.9143 - val_loss: 2.6659 - val_acc: 0.5385\n",
      "Epoch 21/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1353 - acc: 0.9474 \n",
      "Epoch 00021: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.1748 - acc: 0.9286 - val_loss: 2.4500 - val_acc: 0.5385\n",
      "Epoch 22/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2142 - acc: 0.8906 \n",
      "Epoch 00022: val_acc did not improve from 0.53846\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.2272 - acc: 0.9000 - val_loss: 2.2447 - val_acc: 0.5385\n",
      "Epoch 23/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1878 - acc: 0.8947\n",
      "Epoch 00023: val_acc did not improve from 0.53846\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.1564 - acc: 0.9429 - val_loss: 2.0886 - val_acc: 0.5385\n",
      "Epoch 24/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2136 - acc: 0.8906 \n",
      "Epoch 00024: val_acc improved from 0.53846 to 0.57692, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.2214 - acc: 0.8857 - val_loss: 1.9245 - val_acc: 0.5769\n",
      "Epoch 25/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1426 - acc: 0.9737\n",
      "Epoch 00025: val_acc did not improve from 0.57692\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.2357 - acc: 0.9000 - val_loss: 1.7911 - val_acc: 0.5769\n",
      "Epoch 26/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.3604 - acc: 0.8158 \n",
      "Epoch 00026: val_acc did not improve from 0.57692\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.2756 - acc: 0.8714 - val_loss: 1.6755 - val_acc: 0.5769\n",
      "Epoch 27/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.2585 - acc: 0.9737\n",
      "Epoch 00027: val_acc did not improve from 0.57692\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.2376 - acc: 0.9429 - val_loss: 1.5532 - val_acc: 0.5769\n",
      "Epoch 28/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1622 - acc: 0.9211\n",
      "Epoch 00028: val_acc did not improve from 0.57692\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.1401 - acc: 0.9429 - val_loss: 1.4282 - val_acc: 0.5769\n",
      "Epoch 29/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.1178 - acc: 0.9688 \n",
      "Epoch 00029: val_acc improved from 0.57692 to 0.65385, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 27s 9s/step - loss: 0.1411 - acc: 0.9714 - val_loss: 1.3060 - val_acc: 0.6538\n",
      "Epoch 30/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1414 - acc: 0.9211\n",
      "Epoch 00030: val_acc did not improve from 0.65385\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1964 - acc: 0.9143 - val_loss: 1.2162 - val_acc: 0.6538\n",
      "Epoch 31/100\n",
      "2/3 [===================>..........] - ETA: 9s - loss: 0.2606 - acc: 0.9375 \n",
      "Epoch 00031: val_acc improved from 0.65385 to 0.69231, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 38s 13s/step - loss: 0.2223 - acc: 0.9479 - val_loss: 1.1342 - val_acc: 0.6923\n",
      "Epoch 32/100\n",
      "2/3 [===================>..........] - ETA: 6s - loss: 0.1579 - acc: 0.9531 \n",
      "Epoch 00032: val_acc improved from 0.69231 to 0.73077, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1623 - acc: 0.9571 - val_loss: 1.0552 - val_acc: 0.7308\n",
      "Epoch 33/100\n",
      "2/3 [===================>..........] - ETA: 6s - loss: 0.1074 - acc: 0.9531 \n",
      "Epoch 00033: val_acc improved from 0.73077 to 0.76923, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.2430 - acc: 0.9429 - val_loss: 0.9683 - val_acc: 0.7692\n",
      "Epoch 34/100\n",
      "2/3 [===================>..........] - ETA: 3s - loss: 0.1676 - acc: 0.9474\n",
      "Epoch 00034: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.1606 - acc: 0.9286 - val_loss: 0.9013 - val_acc: 0.7692\n",
      "Epoch 35/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1939 - acc: 0.9531 \n",
      "Epoch 00035: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1671 - acc: 0.9583 - val_loss: 0.8395 - val_acc: 0.7692\n",
      "Epoch 36/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1561 - acc: 0.9375 \n",
      "Epoch 00036: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1751 - acc: 0.9286 - val_loss: 0.7828 - val_acc: 0.7692\n",
      "Epoch 37/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2101 - acc: 0.8750 \n",
      "Epoch 00037: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1831 - acc: 0.9062 - val_loss: 0.7386 - val_acc: 0.7692\n",
      "Epoch 38/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1894 - acc: 0.9219 \n",
      "Epoch 00038: val_acc did not improve from 0.76923\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1547 - acc: 0.9479 - val_loss: 0.6945 - val_acc: 0.7692\n",
      "Epoch 39/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1359 - acc: 0.9688 \n",
      "Epoch 00039: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.2163 - acc: 0.9375 - val_loss: 0.6521 - val_acc: 0.7692\n",
      "Epoch 40/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1030 - acc: 0.9737 \n",
      "Epoch 00040: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1101 - acc: 0.9571 - val_loss: 0.6052 - val_acc: 0.7692\n",
      "Epoch 41/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2304 - acc: 0.9474\n",
      "Epoch 00041: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1665 - acc: 0.9714 - val_loss: 0.5621 - val_acc: 0.7692\n",
      "Epoch 42/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2226 - acc: 0.8684\n",
      "Epoch 00042: val_acc did not improve from 0.76923\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2240 - acc: 0.8857 - val_loss: 0.5284 - val_acc: 0.7692\n",
      "Epoch 43/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1276 - acc: 0.9211\n",
      "Epoch 00043: val_acc did not improve from 0.76923\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1220 - acc: 0.9429 - val_loss: 0.4946 - val_acc: 0.7692\n",
      "Epoch 44/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2408 - acc: 0.9211\n",
      "Epoch 00044: val_acc improved from 0.76923 to 0.80769, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 26s 9s/step - loss: 0.2001 - acc: 0.9571 - val_loss: 0.4707 - val_acc: 0.8077\n",
      "Epoch 45/100\n",
      "2/3 [===================>..........] - ETA: 3s - loss: 0.2122 - acc: 0.9211\n",
      "Epoch 00045: val_acc did not improve from 0.80769\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.1901 - acc: 0.9429 - val_loss: 0.4415 - val_acc: 0.8077\n",
      "Epoch 46/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1192 - acc: 0.9531 \n",
      "Epoch 00046: val_acc did not improve from 0.80769\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1577 - acc: 0.9429 - val_loss: 0.4139 - val_acc: 0.8077\n",
      "Epoch 47/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1783 - acc: 0.9211 \n",
      "Epoch 00047: val_acc improved from 0.80769 to 0.84615, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 24s 8s/step - loss: 0.2262 - acc: 0.8857 - val_loss: 0.3918 - val_acc: 0.8462\n",
      "Epoch 48/100\n",
      "2/3 [===================>..........] - ETA: 6s - loss: 0.2405 - acc: 0.9062 \n",
      "Epoch 00048: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.2478 - acc: 0.9000 - val_loss: 0.3686 - val_acc: 0.8462\n",
      "Epoch 49/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1680 - acc: 0.9211\n",
      "Epoch 00049: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1892 - acc: 0.9286 - val_loss: 0.3492 - val_acc: 0.8462\n",
      "Epoch 50/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2342 - acc: 0.9375 \n",
      "Epoch 00050: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1988 - acc: 0.9375 - val_loss: 0.3342 - val_acc: 0.8462\n",
      "Epoch 51/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1305 - acc: 0.9474\n",
      "Epoch 00051: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1581 - acc: 0.9143 - val_loss: 0.3167 - val_acc: 0.8462\n",
      "Epoch 52/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1347 - acc: 0.9375 \n",
      "Epoch 00052: val_acc did not improve from 0.84615\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1859 - acc: 0.9286 - val_loss: 0.2959 - val_acc: 0.8462\n",
      "Epoch 53/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.3217 - acc: 0.8421 \n",
      "Epoch 00053: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2561 - acc: 0.9000 - val_loss: 0.2810 - val_acc: 0.8462\n",
      "Epoch 54/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2101 - acc: 0.8947\n",
      "Epoch 00054: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1870 - acc: 0.9143 - val_loss: 0.2669 - val_acc: 0.8462\n",
      "Epoch 55/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2266 - acc: 0.9062 \n",
      "Epoch 00055: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1851 - acc: 0.9271 - val_loss: 0.2573 - val_acc: 0.8462\n",
      "Epoch 56/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1418 - acc: 0.9531 \n",
      "Epoch 00056: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.2162 - acc: 0.9429 - val_loss: 0.2437 - val_acc: 0.8462\n",
      "Epoch 57/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.4041 - acc: 0.8684\n",
      "Epoch 00057: val_acc did not improve from 0.84615\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.2994 - acc: 0.9000 - val_loss: 0.2333 - val_acc: 0.8462\n",
      "Epoch 58/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2137 - acc: 0.9219 \n",
      "Epoch 00058: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1675 - acc: 0.9479 - val_loss: 0.2243 - val_acc: 0.8462\n",
      "Epoch 59/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1308 - acc: 0.9531 \n",
      "Epoch 00059: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1875 - acc: 0.9271 - val_loss: 0.2177 - val_acc: 0.8462\n",
      "Epoch 60/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1428 - acc: 0.9474\n",
      "Epoch 00060: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1281 - acc: 0.9714 - val_loss: 0.2080 - val_acc: 0.8462\n",
      "Epoch 61/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1644 - acc: 0.9219 \n",
      "Epoch 00061: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1804 - acc: 0.9286 - val_loss: 0.1987 - val_acc: 0.8462\n",
      "Epoch 62/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1264 - acc: 0.9688 \n",
      "Epoch 00062: val_acc did not improve from 0.84615\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1397 - acc: 0.9479 - val_loss: 0.1932 - val_acc: 0.8462\n",
      "Epoch 63/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1119 - acc: 0.9737 \n",
      "Epoch 00063: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1171 - acc: 0.9714 - val_loss: 0.1840 - val_acc: 0.8462\n",
      "Epoch 64/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2000 - acc: 0.9219 \n",
      "Epoch 00064: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1905 - acc: 0.9062 - val_loss: 0.1795 - val_acc: 0.8462\n",
      "Epoch 65/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.0999 - acc: 0.9531 \n",
      "Epoch 00065: val_acc did not improve from 0.84615\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1400 - acc: 0.9479 - val_loss: 0.1756 - val_acc: 0.8462\n",
      "Epoch 66/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2964 - acc: 0.8158\n",
      "Epoch 00066: val_acc improved from 0.84615 to 0.88462, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 24s 8s/step - loss: 0.2370 - acc: 0.8571 - val_loss: 0.1678 - val_acc: 0.8846\n",
      "Epoch 67/100\n",
      "2/3 [===================>..........] - ETA: 6s - loss: 0.1091 - acc: 0.9844 \n",
      "Epoch 00067: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.0932 - acc: 0.9857 - val_loss: 0.1602 - val_acc: 0.8846\n",
      "Epoch 68/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.5101 - acc: 0.8684 \n",
      "Epoch 00068: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.3256 - acc: 0.9286 - val_loss: 0.1543 - val_acc: 0.8846\n",
      "Epoch 69/100\n",
      "2/3 [===================>..........] - ETA: 8s - loss: 0.2312 - acc: 0.9062 \n",
      "Epoch 00069: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 29s 10s/step - loss: 0.2201 - acc: 0.9167 - val_loss: 0.1514 - val_acc: 0.8846\n",
      "Epoch 70/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2653 - acc: 0.9737\n",
      "Epoch 00070: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2071 - acc: 0.9571 - val_loss: 0.1450 - val_acc: 0.8846\n",
      "Epoch 71/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1611 - acc: 0.9737\n",
      "Epoch 00071: val_acc did not improve from 0.88462\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2085 - acc: 0.9286 - val_loss: 0.1389 - val_acc: 0.8846\n",
      "Epoch 72/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1521 - acc: 0.9474\n",
      "Epoch 00072: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2063 - acc: 0.9143 - val_loss: 0.1340 - val_acc: 0.8846\n",
      "Epoch 73/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2151 - acc: 0.9219 \n",
      "Epoch 00073: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1683 - acc: 0.9286 - val_loss: 0.1293 - val_acc: 0.8846\n",
      "Epoch 74/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1255 - acc: 0.9737 \n",
      "Epoch 00074: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1343 - acc: 0.9429 - val_loss: 0.1244 - val_acc: 0.8846\n",
      "Epoch 75/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2785 - acc: 0.9375 \n",
      "Epoch 00075: val_acc did not improve from 0.88462\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.2237 - acc: 0.9479 - val_loss: 0.1227 - val_acc: 0.8846\n",
      "Epoch 76/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.3021 - acc: 0.8421 \n",
      "Epoch 00076: val_acc improved from 0.88462 to 0.92308, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 24s 8s/step - loss: 0.2396 - acc: 0.8714 - val_loss: 0.1180 - val_acc: 0.9231\n",
      "Epoch 77/100\n",
      "2/3 [===================>..........] - ETA: 3s - loss: 0.2306 - acc: 0.9211 \n",
      "Epoch 00077: val_acc did not improve from 0.92308\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.2321 - acc: 0.9143 - val_loss: 0.1138 - val_acc: 0.9231\n",
      "Epoch 78/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2748 - acc: 0.9062 \n",
      "Epoch 00078: val_acc improved from 0.92308 to 0.96154, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.3471 - acc: 0.9000 - val_loss: 0.1099 - val_acc: 0.9615\n",
      "Epoch 79/100\n",
      "2/3 [===================>..........] - ETA: 6s - loss: 0.2133 - acc: 0.9219 \n",
      "Epoch 00079: val_acc did not improve from 0.96154\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.2072 - acc: 0.9143 - val_loss: 0.1062 - val_acc: 0.9615\n",
      "Epoch 80/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2497 - acc: 0.9474\n",
      "Epoch 00080: val_acc improved from 0.96154 to 1.00000, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1975 - acc: 0.9429 - val_loss: 0.1024 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "2/3 [===================>..........] - ETA: 3s - loss: 0.1962 - acc: 0.9211\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.1546 - acc: 0.9429 - val_loss: 0.0987 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "2/3 [===================>..........] - ETA: 8s - loss: 0.1264 - acc: 0.9531 \n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1806 - acc: 0.9429 - val_loss: 0.0952 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "2/3 [===================>..........] - ETA: 5s - loss: 0.1306 - acc: 1.0000\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 24s 8s/step - loss: 0.2196 - acc: 0.9143 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2962 - acc: 0.8421 \n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2374 - acc: 0.8714 - val_loss: 0.0891 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1552 - acc: 0.9737\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1368 - acc: 0.9571 - val_loss: 0.0870 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.0995 - acc: 0.9211 \n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1069 - acc: 0.9286 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1052 - acc: 0.9688 \n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1659 - acc: 0.9271 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1490 - acc: 0.9737 \n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2104 - acc: 0.9143 - val_loss: 0.0831 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1571 - acc: 0.9688 \n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 28s 9s/step - loss: 0.1590 - acc: 0.9688 - val_loss: 0.0835 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2251 - acc: 0.8947\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1829 - acc: 0.9429 - val_loss: 0.0819 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1599 - acc: 0.9211 \n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1549 - acc: 0.9429 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.1330 - acc: 0.9737\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1184 - acc: 0.9857 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1887 - acc: 0.9219 \n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.2358 - acc: 0.9143 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.1487 - acc: 0.9531 \n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.1702 - acc: 0.9429 - val_loss: 0.0762 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2589 - acc: 0.9375 \n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "3/3 [==============================] - 29s 10s/step - loss: 0.2080 - acc: 0.9375 - val_loss: 0.0767 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2869 - acc: 0.9062 \n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 29s 10s/step - loss: 0.2246 - acc: 0.9375 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "2/3 [===================>..........] - ETA: 8s - loss: 0.2049 - acc: 0.9531 \n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.2214 - acc: 0.9429 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "2/3 [===================>..........] - ETA: 4s - loss: 0.2060 - acc: 0.9474 \n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.1624 - acc: 0.9571 - val_loss: 0.0751 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2512 - acc: 0.8906 \n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "3/3 [==============================] - 29s 10s/step - loss: 0.1994 - acc: 0.9271 - val_loss: 0.0756 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "2/3 [===================>..........] - ETA: 7s - loss: 0.2500 - acc: 0.8906 \n",
      "Epoch 00100: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "3/3 [==============================] - 23s 8s/step - loss: 0.2167 - acc: 0.9000 - val_loss: 0.0745 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                              data_aug,\n",
    "                              steps_per_epoch=len(trainX)// batch_size, # parte inteira da divisão\n",
    "                              validation_data=(testX, testY),\n",
    "                              validation_steps=len(testX) // batch_size,# parte inteira da divisão\n",
    "                              callbacks=callbacks,\n",
    "                              epochs=epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISANDO DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(testX)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(testY,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.0000\n",
      "Sensitividade: 1.0000\n",
      "Especificidade: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(\"Acurácia: {:.4f}\".format(acc))\n",
    "print(\"Sensitividade: {:.4f}\".format(sensitivity))\n",
    "print(\"Especificidade: {:.4f}\".format(specificity))\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm ,  figsize=(6, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detector COVID-19 automático 96,15% de Acurácia.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também estamos obtendo 100% de sensibilidade e 92% de especificidade, o que implica que:\n",
    "\n",
    "- Sensibilidade, capacidade indentificar caso positivo de COVID-19 com o modelo é de 100%.\n",
    "\n",
    "\n",
    "- Especificidade, capacidade indentificar caso Não-Positivo de COVID-19 com o modelo é de 92,31%.\n",
    "\n",
    "\n",
    "- Como mostra nosso gráfico de histórico de treinamento, nossa rede não está adaptando demais, apesar de ter dados de treinamento limitado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
