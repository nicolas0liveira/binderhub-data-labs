{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e4c7d791-d39c-4247-a950-8f541b2b2b2b"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Classificação de textos com *scikit-learn*\n",
    "por Prof. Sanderson Macedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "918ce0e7-8f69-4d3c-8106-d3c5264c94e3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<hr size=5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca5fe97a-0224-4915-a59d-38e6baa218a2"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "\n",
    "1. Representar um texto como dados numéricos\n",
    "2. Ler o *dataset* de texto no Pandas\n",
    "2. Vetorizar nossso *dataset*\n",
    "4. Construir e avaliar um modelo\n",
    "5. Comparar modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d2e20804-da18-483c-bd40-8c25e2d4699c"
    }
   },
   "outputs": [],
   "source": [
    "##Importando pandas e numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "76e5a32a-69c4-4dc5-a66b-23d2cca623af"
    }
   },
   "source": [
    "## 1. Definindo um vetor de textos \n",
    "Os textos do vetor podem ser adquiridos por meio da leitura de \n",
    "pdf's, doc's, twitter's... etc.\n",
    "\n",
    "Esses textos serão a base de treinamento\n",
    "para a classificação do sentimento de um novo texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "56bab267-0993-4d7a-9436-11bc5de3d1d3"
    }
   },
   "outputs": [],
   "source": [
    "train = [\n",
    "    'Eu te amo',\n",
    "    'Você é algo assim... é tudo pra mim. Ao meu amor... Amor!',\n",
    "    'Eu te odeio muito, você não presta!',\n",
    "    'Não gosto de você'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fc1fc669-a603-412e-8855-837d750718ff"
    }
   },
   "source": [
    "## 2. Definindo um vetor de sentimentos\n",
    "Criaremos um vetor de sentimentos chamado **_felling_**. \n",
    "\n",
    "Cada posição do vetor **_felling_** representa o sentimento **BOM** (1) ou **RUIM** (0) para os textos que passamos ao vetor **_train_**.\n",
    "\n",
    "Por exemplo: a frase da primeira posição do vetor **_train_**:\n",
    "\n",
    "> 'Eu te amo'\n",
    "\n",
    "Foi classificada como sendo um texto **BOM**:\n",
    "\n",
    "> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "68a4277e-e38c-42ac-8528-0b90efe86e42"
    }
   },
   "outputs": [],
   "source": [
    "felling = [1,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f43ff54a-e843-4a35-8447-66665f36ebca"
    }
   },
   "source": [
    "## 3. Análise de texto com _scikit-learn_.\n",
    "\n",
    "Texto de [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Análise de texto é um campo de aplicação importante para algoritmos de aprendizado de máquina. No entanto, uma sequência de símbolos não podem ser passada diretamente aos algoritmos de Machine Learning, pois a maioria deles espera vetores de características numéricas com um tamanho fixo, em vez de documentos de texto com comprimento variável.\n",
    "\n",
    "Mas nesse caso podemos realizar algumas transformações de para poder manipular textos em algoritmos de aprendizagem.\n",
    "\n",
    "Portanto, aqui utilizaremos a [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "para converter textos em uma matriz que expressará a quantidade \"tokens\" dos textos.\n",
    "\n",
    "Importamos a classe e criamos uma instância chamada **_vect_**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1ada59d7-f1ba-4625-8999-b8af5aaf461c"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "154ef867-0532-45ad-9910-c87f6711d1b0"
    }
   },
   "source": [
    "## 4. Treinamento criando o dicionário.\n",
    "Agora treinamos o algoritmo com o vetor de textos que criamos acima. Chamamos o método **_fit()_** passando o vetor de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eff3a289-8c0d-4374-9400-d988a6b36624"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que o parametro *analyzer* é defindo por padrão como *'word'* na classe *CountVectorizer*. Isso signicica que a classe ignora palavras com menos de dois (2) caracteres e pontuações. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d4093cdd-6b19-4fed-9a01-5ee02f41ca51"
    }
   },
   "source": [
    "## 5. Nosso dicionário de palavras\n",
    "Aqui vamos listar quais palavras forma utilizadas nos textos de **_train_**, formando nosso dicionário de palavras. Nessa listagem as palavras não se repetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3ab9a844-7f38-40c5-a57f-4a2fbf3343ba"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algo',\n",
       " 'amo',\n",
       " 'amor',\n",
       " 'ao',\n",
       " 'assim',\n",
       " 'de',\n",
       " 'eu',\n",
       " 'gosto',\n",
       " 'meu',\n",
       " 'mim',\n",
       " 'muito',\n",
       " 'não',\n",
       " 'odeio',\n",
       " 'pra',\n",
       " 'presta',\n",
       " 'te',\n",
       " 'tudo',\n",
       " 'você']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## examinando o dicionário criado em ordem alfabética.\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Criação de uma matriz de ocorrência\n",
    "\n",
    "\n",
    "\n",
    "A matriz de ocorrência mostra a ocorrência de cada palavra em cada texto passado para o algoritmo que criou o dicionário.\n",
    "Essa transformação cria uma matriz onde:\n",
    "\n",
    "1. Cada linha representa um texto do vetor **_train_** \n",
    "2. Cada coluna uma palavra do dicionário aprendido.\n",
    "3. Se a palavra ocorrer no texto o valor será 1 caso contrário 0.\n",
    "\n",
    "Por exemplo:\n",
    "A primeira linha da matriz é a frase\n",
    "\n",
    "> Eu te amo\n",
    "\n",
    "Essa frase tem somente três(3) palavras **_eu_**, **_te_** e **_amo_** que serão marcados na matriz com a quantidade que ocorrem no texto nesse caso **_1_** e as outras palavras do dicionário serão marcadas pelo valor zero(0), por não estarem no texto.\n",
    "\n",
    "A segunda frase\n",
    "\n",
    "> Você é algo assim... é tudo pra mim. Ao meu amor... Amor!\n",
    "\n",
    "A palavra **_amor_** ocorre duas(2) vezes, por isso que a terceira posição tem o valor 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "34cfd603-24de-4379-9a69-353ba0e50fba"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train_dtm = vect.transform(train)\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um *dataframe*  pandas para visualizar melhor os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2e563c0f-37c5-4861-85c6-9185c20e3507"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>amo</th>\n",
       "      <th>amor</th>\n",
       "      <th>ao</th>\n",
       "      <th>assim</th>\n",
       "      <th>de</th>\n",
       "      <th>eu</th>\n",
       "      <th>gosto</th>\n",
       "      <th>meu</th>\n",
       "      <th>mim</th>\n",
       "      <th>muito</th>\n",
       "      <th>não</th>\n",
       "      <th>odeio</th>\n",
       "      <th>pra</th>\n",
       "      <th>presta</th>\n",
       "      <th>te</th>\n",
       "      <th>tudo</th>\n",
       "      <th>você</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eu te amo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Você é algo assim... é tudo pra mim. Ao meu amor... Amor!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eu te odeio muito, você não presta!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Não gosto de você</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    algo  amo  amor  ao  \\\n",
       "Eu te amo                                              0    1     0   0   \n",
       "Você é algo assim... é tudo pra mim. Ao meu amo...     1    0     2   1   \n",
       "Eu te odeio muito, você não presta!                    0    0     0   0   \n",
       "Não gosto de você                                      0    0     0   0   \n",
       "\n",
       "                                                    assim  de  eu  gosto  meu  \\\n",
       "Eu te amo                                               0   0   1      0    0   \n",
       "Você é algo assim... é tudo pra mim. Ao meu amo...      1   0   0      0    1   \n",
       "Eu te odeio muito, você não presta!                     0   0   1      0    0   \n",
       "Não gosto de você                                       0   1   0      1    0   \n",
       "\n",
       "                                                    mim  muito  não  odeio  \\\n",
       "Eu te amo                                             0      0    0      0   \n",
       "Você é algo assim... é tudo pra mim. Ao meu amo...    1      0    0      0   \n",
       "Eu te odeio muito, você não presta!                   0      1    1      1   \n",
       "Não gosto de você                                     0      0    1      0   \n",
       "\n",
       "                                                    pra  presta  te  tudo  \\\n",
       "Eu te amo                                             0       0   1     0   \n",
       "Você é algo assim... é tudo pra mim. Ao meu amo...    1       0   0     1   \n",
       "Eu te odeio muito, você não presta!                   0       1   1     0   \n",
       "Não gosto de você                                     0       0   0     0   \n",
       "\n",
       "                                                    você  \n",
       "Eu te amo                                              0  \n",
       "Você é algo assim... é tudo pra mim. Ao meu amo...     1  \n",
       "Eu te odeio muito, você não presta!                    1  \n",
       "Não gosto de você                                      1  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names(), index=train)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. esparsividade\n",
    "A matriz de ocorrência é uma matriz normalmente muito esparsa, ou seja, com muitos valores zero. Essa quantidade de zeros na matriz aumenta substâncialmente o processamento das informações para a classificação de um novo texto. Portanto, a matriz esparsa ficará melhor representada pela ocorrência sem os valores zero.\n",
    "A linha abaixo mostra que a matriz é do tipo esparsa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comando anterior mostra os mesmos valores da matriz de ocorrências de palavras só que retirando as não ocorrências.\n",
    "\n",
    "Por exemplo:\n",
    "As três(3) primeiras linhas da impressão do comando se refere a frase:\n",
    "\n",
    "> Eu te amo\n",
    "\n",
    "(0, 1)\t1<br>\n",
    "(0, 6)\t1<br>\n",
    "(0, 15)\t1<br>\n",
    "\n",
    "Essa é a frase zero(0) ou seja a primeira frase. os valores 1, 6, 16 é posição da matriz onde ocorres as palavras [amo, eu, te] (em ordem alfabética), e os valores 1 são as quantidades de ocorrências de cada palavra nessa frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "95d91cb6-e3f8-4b4b-ab82-900f8719f4db"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 15)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 17)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 17)\t1\n"
     ]
    }
   ],
   "source": [
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente muitos documentos usarão somente um pequeno subconjuto das palavras do nosso *dicionário*, por isso a matriz resultante terá vários valores zerados nas palavras (basicamente mais de 99% delas)\n",
    "\n",
    "Por exemplo, um conjunto de **dez mil (10.000)** pequenos textos (tais como emails) terá um vocabulário da ordem de **cem mil (100.000)** palavras únicas. Porém cada texto normalmente usará somente **cem (100)** palavras únicas individualmente   \n",
    "\n",
    "Visando o armazenamento dessa matri e a aceleração de operações, algoritimos normalmente usam a representação esparsa como a implementação disponível no pacote **_scipy.sparse_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Classificações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Classificando um novo texto\n",
    "\n",
    "Nosso objetivo é inferir se um novo texto é **BOM** ou **RUIM**\n",
    "tendo como base os textos anteriormente classificados.\n",
    "o vetor ***novo_texto*** contém um novo texto obtido e que será classificado por nosso algoritmo de aprendizagem de máquina.\n",
    "\n",
    "Basicamente classificaremos o texto com o algoritmo ***KNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novo_texto = ['te odeio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando a matriz de ocorrência para o novo texto\n",
    "A matriz ***simple_test_dtm*** é que será usada para a nova classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>amo</th>\n",
       "      <th>amor</th>\n",
       "      <th>ao</th>\n",
       "      <th>assim</th>\n",
       "      <th>de</th>\n",
       "      <th>eu</th>\n",
       "      <th>gosto</th>\n",
       "      <th>meu</th>\n",
       "      <th>mim</th>\n",
       "      <th>muito</th>\n",
       "      <th>não</th>\n",
       "      <th>odeio</th>\n",
       "      <th>pra</th>\n",
       "      <th>presta</th>\n",
       "      <th>te</th>\n",
       "      <th>tudo</th>\n",
       "      <th>você</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>te odeio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algo  amo  amor  ao  assim  de  eu  gosto  meu  mim  muito  não  \\\n",
       "te odeio     0    0     0   0      0   0   0      0    0    0      0    0   \n",
       "\n",
       "          odeio  pra  presta  te  tudo  você  \n",
       "te odeio      1    0       0   1     0     0  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_test_dtm = vect.transform(novo_texto)\n",
    "\n",
    "##criando a visualização da matriz de ocorrência\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names(), index=novo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Classificador KNN\n",
    "\n",
    "Importando o classificador KNN do scikit-learn\n",
    "\n",
    "Referência sobre o classificador KNN você pode acessar o [wikpedia-KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) e a referência do [KNN no scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## importanto o classificador\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o classificador KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(simple_train_dtm, felling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Gerando uma classificação\n",
    "Para isso utiliza-se o método ***predict()*** do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fell = knn.predict(simple_test_dtm)[0]\n",
    "fell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom sentimento\n"
     ]
    }
   ],
   "source": [
    "if fell==1:\n",
    "    print(\"Bom sentimento\")\n",
    "else:\n",
    "    print(\"Mal sentimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms = pd.read_table('sms.tsv', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}